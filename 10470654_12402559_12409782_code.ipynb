{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR1 - Programming Assignment - Part B\n",
    "#### Elias Kassapis (12409782)\n",
    "#### Stijn Verdenius (10470654)\n",
    "#### Konstantin Todorov (12402559)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook an experiment is implemented, with the goal to obtain the number of interleaving impressions necessary to statistically say ranking algorithm E outperforms current standard algorithm P. To reach this goal a class structure has been set up that produces a table with the needed number of online impressions, given the initial offline ERR-score interval in offline testing. This is done in six steps:\n",
    "\n",
    "- Step 1: Generating ranking pairs for E & P, using all possible permutations of a number of documents with binary relevance\n",
    "- Step 2: Filtering the generated ranking pairs on the part that produces promising results for E only. Subsequently dividing in bins of small intervals of ERR-score.\n",
    "- Step 3: Creating interleavings from these intervals with two models: team-draft- and probabilistic interleaving\n",
    "- Step 4: Learning to imitate user behaviour using actual user log-files, and therewith training a probabilistic- and random click model\n",
    "- Step 5: Combining Interleaving and Click models to do experiment in parallel fashion\n",
    "- Step 6: Using results to obtain needed number of impressions for statistical significance\n",
    "\n",
    "The Experiment has been set up using a number of classes, each representing a part of the experiment. For example, there are classes for interleavings and click models, as well as for each step in the process. Subsequently, all classes are combined in the main function, making sure the setup is modular, thus allowing quick changes to be made. Finally, results are demonstrated and analysed, to validate the effectivness of the PBM, comparte the effect of the interleaving algorithms and finally to compare sample size.\n",
    "\n",
    "Directly underneath the code can be found with chapters corresponding to the steps mentioned above, after which the analysis can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from typing import List\n",
    "from functools import lru_cache\n",
    "from copy import deepcopy\n",
    "from random import choice, random\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "import scipy.stats\n",
    "import cProfile, pstats, io\n",
    "import os\n",
    "\n",
    "\n",
    "# ### DEBUG MODE\n",
    "# # to add debugging, open terminal and type 'tail -1000f debug.txt'. Also uncomment next line\n",
    "# debug = open(\"debug.txt\", \"w\")\n",
    "# # you can then write to terminal with the following python command: debug.write(\"something \\n\")\n",
    "\n",
    "\n",
    "### GLOBAL CONSTANTS\n",
    "\n",
    "# Caching\n",
    "CACHING_ON = False\n",
    "\n",
    "# Number of docs created\n",
    "DATABASE_SIZE = 6\n",
    "\n",
    "# Gamma's get trained on this many docs:\n",
    "GAMMA_SIZE = 3 # also defines cutoff\n",
    "\n",
    "\n",
    "### UTILS\n",
    "\n",
    "def softmax(distribution):\n",
    "    \"\"\" used to restore probability constraint of summing to 1 when elements are removed \"\"\"\n",
    "\n",
    "    summation = sum(distribution)\n",
    "    return [float(x / summation) for x in distribution]\n",
    "\n",
    "@lru_cache(maxsize=3200)\n",
    "def difference_to_err_table_position(difference: float) -> int:\n",
    "    # if difference < 0.05 or \n",
    "    if difference > 0.95:\n",
    "        raise Exception(\"Invalid difference\")\n",
    "    elif difference < 0.1:\n",
    "        return 0\n",
    "    elif difference < 0.2:\n",
    "        return 1\n",
    "    elif difference < 0.3:\n",
    "        return 2\n",
    "    elif difference < 0.4:\n",
    "        return 3\n",
    "    elif difference < 0.5:\n",
    "        return 4\n",
    "    elif difference < 0.6:\n",
    "        return 5\n",
    "    elif difference < 0.7:\n",
    "        return 6\n",
    "    elif difference < 0.8:\n",
    "        return 7\n",
    "    elif difference < 0.9:\n",
    "        return 8\n",
    "    else:\n",
    "        return 9\n",
    "\n",
    "def initialize_err_table():\n",
    "    err_table = {\n",
    "        0: [],\n",
    "        1: [],\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: [],\n",
    "        6: [],\n",
    "        7: [],\n",
    "        8: [],\n",
    "        9: []\n",
    "    }\n",
    "\n",
    "    return err_table\n",
    "\n",
    "# check\n",
    "if (GAMMA_SIZE > 10):\n",
    "    GAMMA_SIZE = 10\n",
    "elif (GAMMA_SIZE < 1):\n",
    "    GAMMA_SIZE = 1\n",
    "    \n",
    "\n",
    "def split_to_chunks(list_to_split, chunks_size):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(list_to_split), chunks_size):\n",
    "        chunks.append(list_to_split[i:i + chunks_size])\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def average_chunks(list_to_split, max_chunks):\n",
    "    chunks_size = math.ceil(len(list_to_split) / max_chunks)\n",
    "    chunks = split_to_chunks(list_to_split, chunks_size)\n",
    "\n",
    "    result = []\n",
    "    for chunk in chunks:\n",
    "        chunk_average = np.average(chunk)\n",
    "        result.append(chunk_average)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA MANAGEMENT\n",
    "\n",
    "class Saver():\n",
    "\n",
    "    def __init__(self, directory, caching=False):\n",
    "        self.directory = directory\n",
    "        self.caching = caching\n",
    "        self.notified = False\n",
    "\n",
    "    def save_python_obj(self, obj, name):\n",
    "        if (not self.caching):\n",
    "            if (not self.notified):\n",
    "                print(\"WARNING: caching disabled, nothing will be pickled. See boolean CACHING_ON on top of notebook\")\n",
    "                self.notified = True\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            with open(self.directory + name+\".pickle\", 'wb') as handle:\n",
    "                pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            print(\"Saved {}\".format(name))\n",
    "        except:\n",
    "            print(\"Failed saving {}, continue anyway\".format(name))\n",
    "\n",
    "    def load_python_obj(self, name):\n",
    "        if (not self.caching):\n",
    "            if (not self.notified):\n",
    "                print(\"WARNING: caching disabled, nothing will be pickled. See boolean CACHING_ON on top of notebook\")\n",
    "                self.notified = True\n",
    "            raise FileNotFoundError(\"Caching disabled\")\n",
    "        \n",
    "        obj = None\n",
    "        try:\n",
    "            with (open(self.directory + name+\".pickle\", \"rb\")) as openfile:\n",
    "                obj = pickle.load(openfile)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"{} not loaded because file is missing\".format(name))\n",
    "        print(\"Loaded {}\".format(name))\n",
    "        return obj\n",
    "\n",
    "    def load_data_model_1(self):\n",
    "        try:\n",
    "            frame = self.load_python_obj(\"data_model_1\")\n",
    "            print(\"Loaded sucessfully\")\n",
    "            return frame\n",
    "        except FileNotFoundError:\n",
    "\n",
    "            print(\"Building data framework\")\n",
    "\n",
    "            f = open(self.directory+\"YandexRelPredChallenge.txt\", \"r\")\n",
    "            frame = []\n",
    "            for line in f:\n",
    "\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "\n",
    "                elements = line.split(\"\t\")\n",
    "\n",
    "                if (elements[2] == \"C\"):\n",
    "                    dictionary = {\"SessionID\": int(elements[0]),\n",
    "                                  \"TimePassed\": int(elements[1]),\n",
    "                                  \"TypeOfAction\": elements[2],\n",
    "                                  \"URLID\": int(elements[3])}\n",
    "                elif (elements[2] == \"Q\"):\n",
    "                    dictionary = {\"SessionID\": int(elements[0]),\n",
    "                                  \"TimePassed\": int(elements[1]),\n",
    "                                  \"TypeOfAction\": elements[2],\n",
    "                                  \"QueryID\": int(elements[3]),\n",
    "                                  \"RegionID\": int(elements[4]),\n",
    "                                  \"ListOfURLs\": [int(x) for x in elements[5:5+GAMMA_SIZE]]\n",
    "\n",
    "                                  }\n",
    "                else:\n",
    "                    raise Exception(\"contenttype not recognized, check load data function\")\n",
    "\n",
    "                frame.append(dictionary)\n",
    "\n",
    "            self.save_python_obj(frame, \"data_model_1\")\n",
    "\n",
    "            print(\"Created data model, this only needs to be done once if caching is on\")\n",
    "            return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General IR-step class\n",
    "used to define the process structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRStep(object):\n",
    "\n",
    "    def __init__(self, name=None, purpose=None, data=None):\n",
    "        self.name = name\n",
    "        self.purpose = purpose\n",
    "        self.data = data\n",
    "\n",
    "    def do_step(self, input_list):\n",
    "        print(\"Starting step {}\".format(self.name))\n",
    "        if (not self.purpose == None):\n",
    "            print(\"Goal:\" + self.purpose + \"\\n\\n\")\n",
    "\n",
    "        result = self.onStart(input_list)\n",
    "        self.onfinish()\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def onStart(self, input_list):\n",
    "        raise Exception(\"method to be overrided by subclass Step#\")\n",
    "\n",
    "    def onfinish(self):\n",
    "        raise Exception(\"method to be overrided by subclass Step#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 implementation:\n",
    "- Getting the rankings out of permutations\n",
    "- Creating the documents\n",
    "- Pairing up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document(object):\n",
    "    \n",
    "    def __init__(self, id, relevance : int):\n",
    "        self.id = id\n",
    "        self.relevance = relevance\n",
    "\n",
    "    def __str__(self):\n",
    "        return str({\"relevance\" : self.relevance_to_int(), \"id\": self.id})\n",
    "        \n",
    "    def relevance_to_int(self):\n",
    "        return self.relevance\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingsStep(IRStep):\n",
    "\n",
    "    def __init__(self, name, purpose, data):\n",
    "        super().__init__(name, purpose, data)\n",
    "\n",
    "    def onStart(self, input_list):\n",
    "        print(\"--- generating documents...\")\n",
    "\n",
    "        documents = self.generate_documents(input_list[0])\n",
    "\n",
    "        print(\"--- generating rankings...\")\n",
    "        p_rankings = itertools.permutations(documents, r=3)\n",
    "        e_rankings = itertools.permutations(documents, r=3)\n",
    "        \n",
    "        print(\"--- generating ranking pairs...\")\n",
    "        rankings_pairs = list(itertools.product(p_rankings, e_rankings))\n",
    "        rankings_pairs = [(list(item[0]), list(item[1])) for item in rankings_pairs]\n",
    "\n",
    "        print(f'--- finished generating {len(rankings_pairs)} ranking pairs')\n",
    "                \n",
    "        return rankings_pairs\n",
    "\n",
    "    def onfinish(self):\n",
    "        print(\"\\n\\nFinished step {}\\n\\n\".format(self.name))\n",
    "\n",
    "    def generate_documents(self, number) -> List[Document]:\n",
    "        current_id = 1\n",
    "        documents = []\n",
    "        \n",
    "        # create NOT_RELEVANT documents \n",
    "        for i in range(number):\n",
    "            documents.append(Document(current_id, 0))\n",
    "            current_id += 1\n",
    "\n",
    "        # create RELEVANT documents\n",
    "        for i in range(number):\n",
    "            documents.append(Document(current_id, 1))\n",
    "            current_id += 1\n",
    "\n",
    "        return documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 implementation:\n",
    "- Evaluating EER score\n",
    "- Binnify pairs\n",
    "- Filtering not promising results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERRStep(IRStep):\n",
    "\n",
    "    def __init__(self, name, purpose, data):\n",
    "        super().__init__(name, purpose, data)\n",
    "\n",
    "    def onStart(self, ranking_pairs):\n",
    "        err_table = initialize_err_table()\n",
    "        \n",
    "        counter = 0\n",
    "        for ranking_pair in ranking_pairs:\n",
    "\n",
    "            try:\n",
    "                p_err = self.calculate_err(ranking_pair[0])\n",
    "                e_err = self.calculate_err(ranking_pair[1])\n",
    "\n",
    "                difference = e_err - p_err\n",
    "\n",
    "                # if E does not outperform P, discard this pair\n",
    "                if difference <= 0:\n",
    "                    continue\n",
    "                counter += 1\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            err_table_position = difference_to_err_table_position(difference)\n",
    "            err_table[err_table_position].append(ranking_pair)\n",
    "\n",
    "#             # DEBUG LINE FOR GETTING LESS DOCS\n",
    "#             if counter >= 100:\n",
    "#                 break\n",
    "\n",
    "        print (f'total ranking pairs left: {counter}')\n",
    "        \n",
    "        return err_table\n",
    "\n",
    "    def onfinish(self):\n",
    "        print(\"Finished step {}\".format(self.name))\n",
    "\n",
    "    def calculate_err(self, documents: [Document]):\n",
    "        err_score = 0\n",
    "\n",
    "        max_relevance = 0\n",
    "        for document in documents:\n",
    "            document_relevance = document.relevance_to_int()\n",
    "            if document_relevance > max_relevance:\n",
    "                max_relevance = document_relevance\n",
    "\n",
    "        for r, document in enumerate(documents):\n",
    "            inner_result = 1\n",
    "            for i in range(r):\n",
    "                theta_i = (2**(documents[i].relevance_to_int()) - 1)/ (2**(max_relevance))\n",
    "                inner_result *= (1 - theta_i)\n",
    "        \n",
    "            theta_r = (2**(document.relevance_to_int()) - 1)/ (2**(max_relevance))\n",
    "            current_err_score = inner_result * theta_r\n",
    "            current_err_score /= (r + 1)\n",
    "            \n",
    "            err_score += current_err_score\n",
    "        \n",
    "        return err_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 implementation:\n",
    "- Interleaving ranking pairs using the following models:\n",
    "    - Team draft interleaving\n",
    "    - Probabilistic interleaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Main interleaving class, parent to specific interleavings\n",
    "\n",
    "Holds some main functionality\n",
    "\"\"\"\n",
    "\n",
    "class Interleaving(object):\n",
    "\n",
    "\n",
    "    def __init__(self, alg_P, alg_E, cutoff=None):\n",
    "        self.alg_P = alg_P\n",
    "        self.alg_E = alg_E\n",
    "        self.ranking2algorithm = {0: \"P\", 1: \"E\"}\n",
    "        self.position2ranking = {}\n",
    "        self.interleaved = []\n",
    "        self.score = {\"E\" : 0, \"P\" : 0}\n",
    "        self._interleave_docs()\n",
    "        if (not cutoff == None):\n",
    "            self.cut_off_at(cutoff)\n",
    "        self.registered_clicks = 0\n",
    "        self.click_history = []\n",
    "\n",
    "    def _interleave_docs(self): #PRIVATE\n",
    "        \"\"\" method contracty to be overrided by child-classes \"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"To be overrided by child class\")\n",
    "\n",
    "    def insertclick(self, position): \n",
    "        \"\"\" stores a click in the interleaving such that later the score can be extracted \"\"\"\n",
    "\n",
    "        self.score[self.ranking2algorithm[self.position2ranking[position]]] += 1\n",
    "        self.registered_clicks += 1\n",
    "        self.click_history.append(position)\n",
    "\n",
    "    def get_interleaved_ranking(self) -> List[Document]: \n",
    "        \"\"\" returns list of documents \"\"\"\n",
    "\n",
    "        return self.interleaved\n",
    "\n",
    "    def get_click_history(self): \n",
    "        return self.click_history\n",
    "\n",
    "    def get_score(self): \n",
    "        \"\"\" returns the score of the two isnerted rankings given currently registered clicks \"\"\"\n",
    "\n",
    "        return self.score\n",
    "\n",
    "    def reset_score(self): \n",
    "        \"\"\" resets counters but leaves interleaving intact \"\"\"\n",
    "\n",
    "        self.score = {\"E\": 0, \"P\": 0}\n",
    "        self.registered_clicks = 0\n",
    "        self.click_history = []\n",
    "\n",
    "    def get_winner(self): \n",
    "        \"\"\" gets winner of interleaving \"\"\"\n",
    "\n",
    "        if (self.score[\"E\"] == self.score[\"P\"]):\n",
    "            return -1\n",
    "        return max(self.score, key=self.score.get)\n",
    "\n",
    "    def cut_off_at(self, cutoff): \n",
    "        \"\"\" cuts off interleaving after certain rank. note: expectations are not recalculated \"\"\"\n",
    "\n",
    "        self.interleaved = self.interleaved[:cutoff]\n",
    "        for key in list(self.position2ranking):\n",
    "            if (key > cutoff):\n",
    "                del self.position2ranking[key]\n",
    "\n",
    "    def _remove_duplicates_from_other_ranking(self, rankings, picked_document, counters, which_second, distributions=None): #PRIVATE\n",
    "        \"\"\" buisiness logic function for removing duplicates out of the ranking whos turn it is not to add a element to the interleaving \"\"\"\n",
    "\n",
    "        # get doc ids from the other ranking and see at what places the doc occurs\n",
    "        doc_ids_second_player = [doc.id for doc in rankings[which_second]]\n",
    "\n",
    "        if (picked_document.id in doc_ids_second_player):\n",
    "            index = doc_ids_second_player.index( picked_document.id)\n",
    "\n",
    "            removed = rankings[which_second].pop(index)\n",
    "            counters[which_second] -= 1\n",
    "\n",
    "            # make sure the removed objects ar identical\n",
    "            assert removed.id == picked_document.id, \"Mistake in prob-interleaving: removing docs from other ranking\"\n",
    "\n",
    "            return self._pop_distribution(index, distributions, which_second)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _pop_distribution(self, index, distributions, which_second): #PRIVATE\n",
    "        \"\"\" to be overrided by child-classes that utilize it, to be ignored by those who don't \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def __str__(self): #TO STRING\n",
    "        return \"Interleaving: \" + str(self.get_interleaved_ranking()) + \", Scores: \" + str(self.score), \", Registered clicks: \"+ str(self.registered_clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProbabilisticInterleaving(Interleaving):\n",
    "\n",
    "    def __init__(self, alg_P, alg_E, distribution, cutoff=None):\n",
    "        self.distribution = distribution\n",
    "        assert len(distribution) == len(alg_P) == len(\n",
    "            alg_E), \"rankings and/or distribution not fo the same lengths\"\n",
    "        self.possible_generators = len(alg_P) * len(alg_E)\n",
    "        self.position2chance = {}\n",
    "        super().__init__(alg_P, alg_E, cutoff)\n",
    "\n",
    "\n",
    "    def _interleave_docs(self): #PRIVATE\n",
    "        \"\"\" implementation of interleaving \"\"\"\n",
    "\n",
    "        counters = [len(self.alg_P), len(self.alg_E)]\n",
    "        rankings = deepcopy([self.alg_P, self.alg_E])\n",
    "        distributions = deepcopy([self.distribution])+deepcopy([self.distribution])\n",
    "\n",
    "        while (sum(counters) > 0):\n",
    "\n",
    "            # flip coin\n",
    "            which_first = choice([1, 0])\n",
    "            which_second = int(not which_first)\n",
    "\n",
    "            # take doc from chosen ranking, skip if it is empty\n",
    "            if (counters[which_first] == 0):\n",
    "                continue\n",
    "            counters[which_first] -= 1\n",
    "            picked_index = np.random.choice(range(len(distributions[which_first])), p=softmax(distributions[which_first]), replace=False)\n",
    "            picked_document = rankings[which_first].pop(picked_index)\n",
    "            chance_which_first = self._pop_distribution(picked_index, distributions, which_first)\n",
    "\n",
    "            # remove from other ranking\n",
    "            chance_which_second = self._remove_duplicates_from_other_ranking(rankings, picked_document, counters, which_second, distributions=distributions)\n",
    "\n",
    "            # insert into interleaving\n",
    "            self.position2chance[len(self.interleaved)] = {which_first: chance_which_first, which_second: chance_which_second}\n",
    "            self.interleaved.append(picked_document)\n",
    "\n",
    "        # make sure both rankings are empty\n",
    "        assert len(rankings[0]) + len(rankings[1]) == 0, \"Mistake: not ranking all docs\"\n",
    "\n",
    "        # complete expectation calculation\n",
    "        self._fill_in_expectations()\n",
    "\n",
    "\n",
    "\n",
    "    def insertclick(self, position): # USE THIS\n",
    "        \"\"\" implementation of click-saving \"\"\"\n",
    "\n",
    "        self.score[\"P\"] += self.position2ranking[position][0]\n",
    "        self.score[\"E\"] += self.position2ranking[position][1]\n",
    "\n",
    "        self.registered_clicks += 1\n",
    "        self.click_history.append(position)\n",
    "\n",
    "    def _pop_distribution(self, index, distributions, which): # PRIVATE\n",
    "        \"\"\" removes element form probability distribution as to be consistent with the documents to be interleaved\"\"\"\n",
    "\n",
    "        return distributions[which].pop(index)\n",
    "\n",
    "    def _fill_in_expectations(self): # PRIVATE\n",
    "        \"\"\" pre-calculates the expectation that is added to both players per new future click \"\"\"\n",
    "\n",
    "        # get all permutations that could've generated this interleaving\n",
    "        chance_of_permutations = []\n",
    "        contribution_permutations = list(itertools.product([0, 1], repeat=len(self.interleaved)))\n",
    "\n",
    "        # get the prior chance of that permutation\n",
    "        for permutation in contribution_permutations:\n",
    "            chance_of_permutations.append(float(sum([self.position2chance[i][r] for i, r in zip(range(len(self.interleaved)), permutation)])/(self.possible_generators*0.5)))\n",
    "\n",
    "        # for both rankings, calculate expectated clicks earned for each future click on each position\n",
    "        for position in range(len(self.interleaved)):\n",
    "\n",
    "            expectations = [0,0]\n",
    "\n",
    "            for chance, permutation in zip(chance_of_permutations, contribution_permutations):\n",
    "                expectations[permutation[position]] += self.position2chance[position][permutation[position]]*chance\n",
    "\n",
    "            self.position2ranking[position] = {0: expectations[0], 1 : expectations[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamDraftInterleaving(Interleaving):\n",
    "\n",
    "    def __init__(self, alg_P, alg_E, cutoff=None):\n",
    "        super().__init__(alg_P, alg_E, cutoff)\n",
    "\n",
    "    def _interleave_docs(self): # PRIVATE\n",
    "        \"\"\" implementation of interleaving \"\"\"\n",
    "\n",
    "        counters = [len(self.alg_P), len(self.alg_E)]\n",
    "        rankings = deepcopy([self.alg_P, self.alg_E])\n",
    "\n",
    "        while(sum(counters) > 0):\n",
    "\n",
    "            # flip coin\n",
    "            which_first = choice([1, 0])\n",
    "            which_second = int(not which_first)\n",
    "\n",
    "            # take doc from chosen ranking, skip if it is empty\n",
    "            if (counters[which_first] == 0):\n",
    "                continue\n",
    "            counters[which_first] -= 1\n",
    "            picked_document = rankings[which_first].pop(0)\n",
    "\n",
    "            self._remove_duplicates_from_other_ranking(rankings, picked_document, counters, which_second)\n",
    "\n",
    "            # insert into interleaving\n",
    "            self.position2ranking[len(self.interleaved)] = which_first\n",
    "            self.interleaved.append(picked_document)\n",
    "\n",
    "        # make sure both rankings are empty\n",
    "        assert len(rankings[0]) + len(rankings[1]) == 0, \"Mistake: not ranking all docs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterleavingsStep(IRStep):\n",
    "\n",
    "    def __init__(self, name, purpose, data):\n",
    "        self.distribution = []\n",
    "        super().__init__(name, purpose, data)\n",
    "\n",
    "    def onStart(self, input_list):\n",
    "\n",
    "        saver = Saver(\"\", caching=CACHING_ON)\n",
    "\n",
    "        try:\n",
    "\n",
    "            return_dict = saver.load_python_obj(\"interleavings\")\n",
    "            return return_dict\n",
    "        except:\n",
    "\n",
    "\n",
    "            probabilistic_interleavings_list = []\n",
    "            team_draft_interleavings_list = []\n",
    "            self.distribution = softmax([norm.pdf(x, 0, 1.5) for x in range(3)])\n",
    "\n",
    "            for number, category in enumerate(input_list.values()):\n",
    "                print (\"\\nStart interleaving category {}\".format(number))\n",
    "\n",
    "                local_probabilistic_interleavings_list = []\n",
    "                local_team_draft_interleavings_list = []\n",
    "\n",
    "\n",
    "                for pair_number, (ranking1, ranking2) in enumerate(category):\n",
    "\n",
    "                    if ((pair_number % int(len(category)/10)) == 0):\n",
    "                        print(\"\\r{} out of {} done\".format(pair_number,  len(category)), end='')\n",
    "\n",
    "                    try:\n",
    "                        probabilistic_interleaving = ProbabilisticInterleaving(ranking1, ranking2, self.distribution)\n",
    "                        probabilistic_interleaving.cut_off_at(GAMMA_SIZE)\n",
    "                        local_probabilistic_interleavings_list.append(probabilistic_interleaving)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        draft_interleaving = TeamDraftInterleaving(ranking1, ranking2)\n",
    "                        draft_interleaving.cut_off_at(GAMMA_SIZE)\n",
    "                        local_team_draft_interleavings_list.append(draft_interleaving)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                probabilistic_interleavings_list.append(local_probabilistic_interleavings_list)\n",
    "                team_draft_interleavings_list.append(local_team_draft_interleavings_list)\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            return_dict = {\"probabilistic\": probabilistic_interleavings_list, \"team_draft\": team_draft_interleavings_list}\n",
    "            saver.save_python_obj(return_dict, \"interleavings\")\n",
    "            return return_dict\n",
    "\n",
    "    def onfinish(self):\n",
    "        print(\"Finished step {}\".format(self.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 implementation:\n",
    "- Learning click model parameters for user-simulation using EM and ML\n",
    "- Defining click models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Click_Model(object):\n",
    "\n",
    "    def __init__(self, parameters, data):\n",
    "        self.parameters = parameters\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        raise NotImplementedError(\"to be overrided\")\n",
    "\n",
    "    def apply(self, interleaving):\n",
    "        raise NotImplementedError(\"to be overrided\")\n",
    "\n",
    "    def get_sc(self):  # clicks for each session\n",
    "        \"\"\"\n",
    "        :param data - in the form of a list of libraries\n",
    "        :return - library where key = Session ID, value = query:[rank, url,click]\n",
    "        \"\"\"\n",
    "        sc = {}  # key = Session ID, value = (clicked rank, url)\n",
    "        current_q = {}\n",
    "        for i in self.data:\n",
    "            if i[\"SessionID\"] not in sc.keys():\n",
    "                sc[i['SessionID']] = {i['QueryID']: []}\n",
    "\n",
    "            if i['TypeOfAction'] == 'Q':\n",
    "                if i['QueryID'] not in sc[i[\"SessionID\"]].keys():\n",
    "                    sc[i['SessionID']][i['QueryID']] = []  # Empty if session does not result in click\n",
    "                current_q = {\"SessionID\": i[\"SessionID\"], \"QueryID\": i['QueryID'], \"ListOfURLs\": i[\"ListOfURLs\"]}\n",
    "                for r, u in enumerate(i[\"ListOfURLs\"]):\n",
    "                    sc[i['SessionID']][i['QueryID']].append([r + 1, u, False])\n",
    "            if i['TypeOfAction'] == 'C':\n",
    "                try:\n",
    "                    cur_q = current_q[\"ListOfURLs\"]\n",
    "                except:\n",
    "                    continue\n",
    "                for r, u in enumerate(cur_q):\n",
    "                    if u == i[\"URLID\"]:\n",
    "                        for sublist in sc[i['SessionID']][current_q['QueryID']]:\n",
    "                            if sublist[1] == u:\n",
    "                                sublist[2] = True\n",
    "        return sc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PBM(Click_Model):\n",
    "\n",
    "    def __init__(self, parameters, data):\n",
    "        super().__init__(parameters, data)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        print(\"Starting training\")\n",
    "\n",
    "        uq = self.get_uq()  # change frame to whatever is the data saved as\n",
    "        sc = self.get_sc()\n",
    "        alphas = self.init_alphas(0.2)  # initializing first alpha\n",
    "        # gammas = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "        gammas = self.parameters\n",
    "        gs = [gammas]\n",
    "        als = [alphas]\n",
    "        convergence_e = 0.01\n",
    "        counter = 0\n",
    "\n",
    "        while 1 == 1:  # infinite loop\n",
    "            current_g = self.gamma_update(als[-1], gs[-1], uq, sc)\n",
    "            # current_g = gamma_update(alphas, gs[counter], uq, sc)\n",
    "            gs.append(current_g)\n",
    "\n",
    "            current_a = self.alpha_update(als[-1], gs[-1], uq, sc)\n",
    "            als.append(current_a)\n",
    "\n",
    "            if (len(als) > 3):\n",
    "                als.pop(0)\n",
    "\n",
    "            if (len(gs) > 3):\n",
    "                gs.pop(0)\n",
    "\n",
    "            counter += 1\n",
    "            print('\\rEM iteration number = {} Trained parameters = {}'.format(counter, current_g), end='')\n",
    "            if np.linalg.norm(np.array(gs[-1]) - np.array(gs[-2])) < convergence_e and counter > 0:  # Convergence criteria\n",
    "                print(\"\\n\")\n",
    "                self.parameters = current_g\n",
    "                return\n",
    "\n",
    "    def apply(self, interleaving):\n",
    "\n",
    "\n",
    "        interleaving.reset_score()\n",
    "\n",
    "        epsilon = 1e-6\n",
    "        interleaving_list = interleaving.get_interleaved_ranking()\n",
    "\n",
    "        for index, document in enumerate(interleaving_list):\n",
    "            relevance = document.relevance_to_int()\n",
    "            if relevance == 1:\n",
    "                alpha = 1 - epsilon\n",
    "            else:\n",
    "                alpha = epsilon\n",
    "\n",
    "            dice = random.random()\n",
    "\n",
    "            evaluated = self.parameters[index] * alpha\n",
    "\n",
    "            if dice <= evaluated:\n",
    "                interleaving.insertclick(index)\n",
    "\n",
    "    def get_uq(self):\n",
    "        \"\"\"\n",
    "        :param data - in the form of a list of libraries\n",
    "        :return - library with key = document url, value = Query id: list of sessions\n",
    "        \"\"\"\n",
    "        uq = {}  # key = document url, value = Query id: list of sessions\n",
    "        for i in self.data:\n",
    "            if i['TypeOfAction'] == 'Q':\n",
    "                for u in i['ListOfURLs']:\n",
    "                    if u not in uq.keys():\n",
    "                        uq[u] = {i['QueryID']: [i['SessionID']]}  # add url and corresponding query and session id\n",
    "                    if u in uq.keys():\n",
    "                        if i['QueryID'] in uq[u].keys():  # check if document vs. query combo already exists\n",
    "                            uq[u][i['QueryID']].append(i['SessionID'])\n",
    "                        else:\n",
    "                            uq[u][i['QueryID']] = [i['SessionID']]\n",
    "        return uq\n",
    "\n",
    "\n",
    "\n",
    "    def init_alphas(self, value):\n",
    "        \"\"\"\n",
    "        :param data -  in the form of a list of libraries\n",
    "        :return - library where key = document, value = query : a_uq\n",
    "        \"\"\"\n",
    "        alphas = {}  # key = document, value = query : a_uq\n",
    "        for f in self.data:\n",
    "            if f['TypeOfAction'] == 'Q':\n",
    "                for u in f[\"ListOfURLs\"]:\n",
    "                    if u not in alphas.keys():\n",
    "                        alphas[u] = {f['QueryID']: value}\n",
    "                    if u in alphas.keys():\n",
    "                        if f['QueryID'] not in alphas[u].keys():\n",
    "                            alphas[u][f['QueryID']] = value\n",
    "        return alphas\n",
    "\n",
    "    def alpha_update(self, alphas, gammas, uq, sc):\n",
    "        \"\"\"\n",
    "        :param alphas - library where key = document, value = query : a_uq\n",
    "        :param gammas - list of 10 parameters\n",
    "        :param uq - library with key = document url, value = Query id: list of sessions\n",
    "        :param sc - library where key = Session ID, value = (clicked rank, url)\n",
    "        :return - update by iterating though all query vs. document seshs\n",
    "        \"\"\"\n",
    "        alpha2 = self.init_alphas(1)\n",
    "        rank = 1  # init rank\n",
    "        click = 0  # initialize click\n",
    "\n",
    "        for document in uq:\n",
    "            for query in uq[document]:\n",
    "                counter = 2\n",
    "\n",
    "                for session in uq[document][query]:\n",
    "                    counter += 1\n",
    "                    for e in sc[session][query]:\n",
    "                        if document == e[1]:\n",
    "                            rank = e[0]\n",
    "                            if e[2] == True:\n",
    "                                click = 1\n",
    "                            else:\n",
    "                                click = 0\n",
    "                            break\n",
    "\n",
    "                    if (click == 0):\n",
    "                        fraction = ((1 - gammas[rank - 1]) * alphas[document][query]) / (\n",
    "                                    1 - (gammas[rank - 1] * alphas[document][query]))  # check alphas[document][query]\n",
    "                        alpha2[document][query] += fraction\n",
    "                    else:\n",
    "                        alpha2[document][query] += 1\n",
    "\n",
    "                alpha2[document][query] /= counter\n",
    "\n",
    "                if alpha2[document][query] < 0:\n",
    "                    raise Exception\n",
    "\n",
    "                if alpha2[document][query] > 1:\n",
    "                    raise Exception\n",
    "        return alpha2\n",
    "\n",
    "    def gamma_update(self, alphas, gammas, uq, sc):\n",
    "        \"\"\"\n",
    "        :param alphas - library where key = document, value = query : a_uq\n",
    "        :param gammas - list of 10 parameters\n",
    "        :param uq - library with key = document url, value = Query id: list of sessions\n",
    "        :param sc - library where key = Session ID, value = (clicked rank, url)\n",
    "        :return - list of updated parameters\n",
    "        \"\"\"\n",
    "        s_r = {key+1 : 0 for key in range(len(gammas))}#, 7: 0, 8: 0, 9: 0, 10: 0}  # sessions per rank (counter)\n",
    "        # counter = 0\n",
    "        gamma = np.zeros(len(gammas))\n",
    "        rank = 1  # initialize rank\n",
    "        click = 0  # initialize click\n",
    "        for document in uq:\n",
    "            for query in uq[document]:\n",
    "                for session in uq[document][query]:\n",
    "                    for e in sc[session][query]:\n",
    "                        if document == e[1]:\n",
    "                            rank = e[0]\n",
    "                            s_r[rank] += 1\n",
    "                            if e[2] == True:\n",
    "                                click = 1\n",
    "                            else:\n",
    "                                click = 0\n",
    "                            break\n",
    "\n",
    "                    if (click == 0):\n",
    "                        fraction = (gammas[rank - 1] * (1 - alphas[document][query])) / (\n",
    "                                    1 - gammas[rank - 1] * alphas[document][query])\n",
    "\n",
    "                        gamma[rank - 1] += fraction\n",
    "                    else:\n",
    "                        gamma[rank - 1] += 1\n",
    "\n",
    "\n",
    "        for g in range(len(gamma)):\n",
    "            gamma[g] /= s_r[g + 1]\n",
    "\n",
    "        return list(np.around(gamma, 4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Random_Click_Model(Click_Model):\n",
    "\n",
    "    def __init__(self, parameters, data):\n",
    "        super().__init__(parameters, data)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        print(\"Starting training\")\n",
    "\n",
    "        sc = self.get_sc()\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for session in sc:\n",
    "            for query in sc[session]:\n",
    "                for document in sc[session][query]:\n",
    "                    if document[2] is True:\n",
    "                        numerator += 1\n",
    "                    denominator += 1\n",
    "\n",
    "        rho = numerator / denominator\n",
    "\n",
    "        self.parameters = rho\n",
    "        print(\"Final rho parameter {}\".format(rho))\n",
    "        return\n",
    "\n",
    "\n",
    "    def apply(self, interleaving):\n",
    "        interleaving.reset_score()\n",
    "\n",
    "        interleaving_list = interleaving.get_interleaved_ranking()\n",
    "\n",
    "        for index, _ in enumerate(interleaving_list):\n",
    "            if random.random() <= self.parameters:\n",
    "                interleaving.insertclick(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserClicksSimulationStep(IRStep):\n",
    "\n",
    "    def __init__(self, name, purpose, data):\n",
    "        super().__init__(name, purpose, data)\n",
    "\n",
    "\n",
    "    def onStart(self, input_list):\n",
    "        length_interleaving = input_list[0]\n",
    "        save_and_load = Saver(\"\", caching=CACHING_ON)\n",
    "\n",
    "        pbm_model = PBM([0.2]*length_interleaving, self.data)\n",
    "        try:\n",
    "            print(\"Attempting loading gamma's from pickle\")\n",
    "            gammas_pbm = save_and_load.load_python_obj(\"gammas_pbm\")\n",
    "            pbm_model.parameters = gammas_pbm\n",
    "        except:\n",
    "            print(\"Did not find gamma's saved in pickle so will retrain and save\")\n",
    "            pbm_model.train()\n",
    "            save_and_load.save_python_obj(pbm_model.parameters, \"gammas_pbm\")\n",
    "\n",
    "        random_model = Random_Click_Model([0.1] * length_interleaving, self.data)\n",
    "        try:\n",
    "            print(\"Attempting loading rho's from pickle\")\n",
    "            rho_random = save_and_load.load_python_obj(\"rho_random\")\n",
    "            random_model.parameters = rho_random\n",
    "        except:\n",
    "            print(\"Did not find rho saved in pickle so will retrain and save\")\n",
    "            random_model.train()\n",
    "            save_and_load.save_python_obj(random_model.parameters, \"rho_random\")\n",
    "\n",
    "        return (pbm_model, random_model)\n",
    "\n",
    "    def onfinish(self):\n",
    "        print(\"Finished step {}\".format(self.name))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 implementation:\n",
    "- Running click simulations for online testing\n",
    "- Capturing experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Experiment(object):\n",
    "    \n",
    "\n",
    "    def __init__(self, interleaving_interval_lists, click_model, name):\n",
    "        self.win_percentage = {}\n",
    "        self.interleaving_interval_lists = interleaving_interval_lists\n",
    "        self.click_model = click_model\n",
    "        self.name = name\n",
    "        self.k = 3000\n",
    "\n",
    "    def run(self):\n",
    "        self.win_percentage = initialize_err_table()\n",
    "        \n",
    "        logging = True\n",
    "\n",
    "        try:\n",
    "            f = open(\"Console_output_multiprocess_{}.txt\".format(self.name), \"w\")\n",
    "        except:\n",
    "            logging = False\n",
    "\n",
    "        # for each interval, for each ranking pair we first \n",
    "        # run interleaving model then the click model k times\n",
    "        for interval_index, interleaving_lists in enumerate(self.interleaving_interval_lists):\n",
    "\n",
    "            if (logging):\n",
    "                f.write(\"INTERVAL\" + str(interval_index) + \"\\n\")\n",
    "                f.flush()\n",
    "\n",
    "            self.win_percentage[interval_index] = []\n",
    "            for interleaving_index, interleaving in enumerate(interleaving_lists):\n",
    "\n",
    "                try:\n",
    "                    if (logging):\n",
    "                        f.write(\"#\" + str(interleaving_index) + \" out of {} in bin {}\\n\".format(str(len(interleaving_lists)), str(interval_index)))\n",
    "                        f.flush()\n",
    "\n",
    "                    wins = 0\n",
    "                    for _ in range(self.k):\n",
    "                        self.click_model.apply(interleaving)\n",
    "\n",
    "                        winner = interleaving.get_winner()\n",
    "                        if winner == \"E\":\n",
    "                            wins += 1\n",
    "\n",
    "                    current_pair_win_percentage = wins / self.k\n",
    "                    self.win_percentage[interval_index].append(current_pair_win_percentage)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        self.win_percentage[\"name\"] = self.name\n",
    "        if (logging):\n",
    "            f.flush()\n",
    "        return self.win_percentage, f, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterleavingSimulationStep(IRStep):\n",
    "    def __init__(self, name, purpose, data):\n",
    "        super().__init__(name, purpose, data)\n",
    "\n",
    "\n",
    "    def onStart(self, input_list):\n",
    "        probabilistic_interleavings_list = input_list[0][\"probabilistic\"]\n",
    "        team_draft_interleavings_list = input_list[0][\"team_draft\"]\n",
    "        probabilistic_click_model = input_list[1][\"probabilistic\"]\n",
    "        random_click_model = input_list[1][\"random\"]\n",
    "\n",
    "        experiment_1 = Experiment((probabilistic_interleavings_list), probabilistic_click_model, 1)\n",
    "        experiment_2 = Experiment((probabilistic_interleavings_list), random_click_model, 2)\n",
    "        experiment_3 = Experiment((team_draft_interleavings_list), probabilistic_click_model, 3)\n",
    "        experiment_4 = Experiment((team_draft_interleavings_list), random_click_model, 4)\n",
    "\n",
    "        save_and_load = Saver(\"\", caching=CACHING_ON)\n",
    "\n",
    "        experiments = [experiment_1, experiment_2, experiment_3, experiment_4]\n",
    "\n",
    "        ignores = []\n",
    "\n",
    "        q = mp.Queue()\n",
    "\n",
    "        processes = [mp.Process(target=self.experimenting, args=(exp, q)) for exp in experiments]\n",
    "\n",
    "        results = [None] * 4\n",
    "\n",
    "        try:\n",
    "            print(\"Running experiments: 1/4\")\n",
    "            result = save_and_load.load_python_obj(\"experiment1\")\n",
    "            results[0] = result\n",
    "            ignores.append(0)\n",
    "        except:\n",
    "            print(\"Started multiprocessing \" + str(1))\n",
    "            processes[0].start()\n",
    "\n",
    "        \n",
    "        try:\n",
    "            print(\"Running experiments: 2/4\")\n",
    "            result = save_and_load.load_python_obj(\"experiment2\")\n",
    "            results[1] = result\n",
    "            ignores.append(1)\n",
    "        except:\n",
    "            print(\"Started multiprocessing \" + str(2))\n",
    "            processes[1].start()\n",
    "\n",
    "        try:\n",
    "            print(\"Running experiments: 3/4\")\n",
    "            result = save_and_load.load_python_obj(\"experiment3\")\n",
    "            results[2] = result\n",
    "            ignores.append(2)\n",
    "        except:\n",
    "            print(\"Started multiprocessing \" + str(3))\n",
    "            processes[2].start()\n",
    "\n",
    "        try:\n",
    "            print(\"Running experiments: 4/4\")\n",
    "            result = save_and_load.load_python_obj(\"experiment4\")\n",
    "            results[3] = result\n",
    "            ignores.append(3)\n",
    "        except:\n",
    "            print(\"Started multiprocessing \" + str(4))\n",
    "            processes[3].start()\n",
    "            \n",
    "            \n",
    "        print(\"Suggestion: in terminal enter 'tail -1000f [LOGFILE]' to follow progress of this part\")\n",
    "\n",
    "        for experiment_index in range(4):\n",
    "            if (experiment_index in ignores):\n",
    "                continue\n",
    "                \n",
    "            print(\"Waiting for result experiment, please be patient\\nSee logfiles of multiprocesses 'Console_output_multiprocess_#.txt'(only available if filewriting is enabled)\\n\")\n",
    "            result = q.get()\n",
    "            index = result[\"name\"]\n",
    "            results[index-1] = result\n",
    "            del result[\"name\"]\n",
    "            print(\"Got result back from experiment {}\\n\".format(index))\n",
    "\n",
    "        for i, p in enumerate(processes):\n",
    "            if (i in ignores):\n",
    "                continue\n",
    "            print(\"Attempting joining back in multiprocess\\n\")\n",
    "            p.join()\n",
    "            print(\"Joined experiment {} back in sucessfully\\n\".format(i+1))\n",
    "\n",
    "\n",
    "        for i, res in zip([1,2,3,4], results):\n",
    "            save_and_load.save_python_obj(res, \"experiment{}\".format(i))\n",
    "\n",
    "        result_1, result_2, result_3, result_4 = results[0], results[1], results[2], results[3]\n",
    "\n",
    "        print(\"\\rRunning experiments: Done!\")\n",
    "\n",
    "        result = {\"pbm\" : {\"probabilistic_interleaving\" : result_1, \"team_draft\" : result_3}, \"random\" : {\"probabilistic_interleaving\" : result_2, \"team_draft\" : result_4}}\n",
    "\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def onfinish(self):\n",
    "        print(\"Finished step {}\".format(self.name))\n",
    "\n",
    "    def experimenting(self, experiment, q):\n",
    "        result, file, logging = experiment.run()\n",
    "        \n",
    "        if (logging):\n",
    "            file.write(\"done experiment\\n\")\n",
    "            file.flush()\n",
    "        \n",
    "        q.put(result)\n",
    "        \n",
    "        if (logging):\n",
    "            file.write(\"put data in queue\\n\")\n",
    "            file.flush()\n",
    "            file.close()\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 implementation:\n",
    "- Interpreting results\n",
    "- Calculating final sample size required for each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SampleSizeStep(IRStep):\n",
    "\n",
    "    def __init__(self, name, purpose, data):\n",
    "        self.alpha = 0.05\n",
    "        self.beta = 0.1\n",
    "        self.p_0 = 0.5\n",
    "        super().__init__(name, purpose, data)\n",
    "\n",
    "\n",
    "    def onStart(self, input_list):\n",
    "\n",
    "        total_table = {}\n",
    "\n",
    "        for cm_index, click_model in enumerate(input_list):\n",
    "\n",
    "            total_table[click_model] = {}\n",
    "\n",
    "            for it_index, interleaving_type in enumerate(input_list[click_model]):\n",
    "                current_index = (cm_index + 1) + (it_index + 1)\n",
    "                print(f'\\rCalculating: {current_index}/4', end='')\n",
    "\n",
    "                total_table[click_model][interleaving_type] = {}\n",
    "\n",
    "                for bin in input_list[click_model][interleaving_type]:\n",
    "\n",
    "                    str_bin = str(bin)\n",
    "\n",
    "                    total_table[click_model][interleaving_type][str_bin] = []\n",
    "                    current_bin = []\n",
    "\n",
    "                    for percentage in input_list[click_model][interleaving_type][bin]:\n",
    "\n",
    "                        proportion_test = self.proportion_test(percentage, self.alpha, self.beta, self.p_0)\n",
    "                        if not proportion_test:\n",
    "                            continue\n",
    "\n",
    "                        current_bin.append(proportion_test)\n",
    "\n",
    "\n",
    "                    max = \"None\"\n",
    "                    min = \"None\"\n",
    "                    median = \"None\"\n",
    "                    mean = \"None\"\n",
    "                    std = \"None\"\n",
    "\n",
    "                    if (len(current_bin) > 0):\n",
    "\n",
    "                        max_chunks = 250\n",
    "                        current_bin = average_chunks(current_bin, max_chunks)\n",
    "                        \n",
    "                        max = np.max(current_bin)\n",
    "                        min = np.min(current_bin)\n",
    "                        median = np.median(current_bin)\n",
    "                        mean = np.mean(current_bin)\n",
    "                        std = np.std(current_bin)\n",
    "\n",
    "                    total_table[click_model][interleaving_type][str_bin] = { \n",
    "                        \"max\" : max, \n",
    "                        \"min\" : min, \n",
    "                        \"median\": median, \n",
    "                        \"mean\" : mean, \n",
    "                        \"std\": std,\n",
    "                        \"list\" : current_bin}\n",
    "\n",
    "        print('\\rCalculating: Done!')\n",
    "        return total_table\n",
    "\n",
    "    @lru_cache(maxsize=320000)\n",
    "    def n(self, alpha, beta, p_0, p_1):\n",
    "\n",
    "        z = (p_1-p_0)/(math.sqrt((p_0*(1-p_0)/self.k)))\n",
    "\n",
    "        nominator = (\n",
    "                    (z-alpha*math.sqrt(p_0*(1-p_0)))\n",
    "                     +\n",
    "                     (z-beta*math.sqrt(p_1*(1-p_1)))\n",
    "                    )\n",
    "\n",
    "        denominator = abs(p_1-p_0)\n",
    "\n",
    "        if (denominator == 0):\n",
    "            # instead of inf for printing reasons\n",
    "            return 9999999999999999\n",
    "\n",
    "        return round(float(nominator/denominator)**2 + float(1/denominator))\n",
    "\n",
    "    @lru_cache(maxsize=320000)\n",
    "    def proportion_test(self, p1, alpha = 0.5, beta = 0.1, p0 = 0.5):\n",
    "        z_alpha = scipy.stats.norm.ppf(1-alpha)\n",
    "        z_beta = scipy.stats.norm.ppf(1-beta)\n",
    "        if p1 == p0:\n",
    "            return None\n",
    "\n",
    "        diff = p1 - p0\n",
    "        sample_size = p0 * (1 - p0) * (z_alpha + z_beta * np.sqrt((p1 * (1-p1))/(p0 *(1-p0)))/(diff))**2\n",
    "        if sample_size==math.inf:\n",
    "            print('INF:', p0, p1, z_alpha, z_beta)\n",
    "\n",
    "        return sample_size\n",
    "\n",
    "    def onfinish(self):\n",
    "        print(\"Finished step {}\".format(self.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together:\n",
    "- Calling all steps\n",
    "- Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "    \n",
    "    save_and_load = Saver(\"\", caching=CACHING_ON)\n",
    "\n",
    "    ## Step 0 : Loading data\n",
    "\n",
    "    data = save_and_load.load_data_model_1()\n",
    "\n",
    "    steps = [\n",
    "        RankingsStep(1, \"Simulate Rankings of Relevance for E and P\", data),\n",
    "        ERRStep(2, \"Calculate the 𝛥measure\", data),\n",
    "        InterleavingsStep(3, \"Implement Team-Draft Interleaving and Probabilistic Interleaving \", data),\n",
    "        UserClicksSimulationStep(4, \"Simulate User Clicks\", data),\n",
    "        InterleavingSimulationStep(5, \"Simulate Interleaving Experiment\", data),\n",
    "        SampleSizeStep(6, \"Compute Sample Size\", data),\n",
    "    ]\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    def do_next_step(input_list, counter):\n",
    "        step_output = steps[counter].do_step(input_list)\n",
    "        counter += 1\n",
    "        return step_output, counter\n",
    "\n",
    "    ## Step 1: Simulate Rankings of Relevance for E and P\n",
    "\n",
    "    rankings_pairs, counter = do_next_step([int(DATABASE_SIZE/2)], counter)\n",
    "\n",
    "    ## Step 2: Calculate the 𝛥measure\n",
    "\n",
    "    err_table, counter = do_next_step(rankings_pairs, counter)\n",
    "\n",
    "    ## Step 3: Implement Team-Draft Interleaving (5pts) and Probabilistic Interleaving (35 points)\n",
    "\n",
    "    interleaving_dictionary, counter = do_next_step(err_table, counter)\n",
    "\n",
    "    ## Step 4: Simulate User Clicks (40 points)\n",
    "\n",
    "    click_models, counter = do_next_step([GAMMA_SIZE], counter)\n",
    "\n",
    "    ## Step 5: Simulate Interleaving Experiment\n",
    "\n",
    "    resulting_dictionary, counter = do_next_step([interleaving_dictionary, {\"probabilistic\": click_models[0], \"random\": click_models[1]}], counter)\n",
    "    \n",
    "    ## Step 6: Compute Sample Size\n",
    "\n",
    "    filled_in_table, counter = do_next_step(resulting_dictionary, counter)\n",
    "\n",
    "    print(\"#######\\n\\n\\nDONE\\n\\n\\n\")\n",
    "\n",
    "    save_and_load.save_python_obj(filled_in_table, \"Final_result\")\n",
    "    \n",
    "    return filled_in_table, resulting_dictionary, pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATING CSV\n",
    "\n",
    "def average_experiment_dict(experiment_dict):\n",
    "    max_chunks = 250\n",
    "    for i in range(10):\n",
    "        if len(experiment_dict[i]) > 0:\n",
    "            experiment_dict[i] = average_chunks(experiment_dict[i], max_chunks)\n",
    "\n",
    "    return experiment_dict\n",
    "\n",
    "def csv_ing_it(final_, percentages):\n",
    "    \n",
    "    print(\"Starting csv export\")\n",
    "    \n",
    "    saver = Saver(\"\", caching=CACHING_ON)\n",
    "\n",
    "    try:\n",
    "        final = saver.load_python_obj(\"Final_result\")\n",
    "    except:\n",
    "        final = final_\n",
    "\n",
    "    try:\n",
    "        percentages1 = average_experiment_dict(saver.load_python_obj(\"experiment1\"))\n",
    "        percentages2 = average_experiment_dict(saver.load_python_obj(\"experiment2\"))\n",
    "        percentages3 = average_experiment_dict(saver.load_python_obj(\"experiment3\"))\n",
    "        percentages4 = average_experiment_dict(saver.load_python_obj(\"experiment4\"))\n",
    "\n",
    "        result = {\"pbm\" : {\"probabilistic_interleaving\" : percentages1, \"team_draft\" : percentages3}, \"random\" : {\"probabilistic_interleaving\" : percentages2, \"team_draft\" : percentages4}}\n",
    "    except:\n",
    "        result = percentages\n",
    "        for key, _ in result.items():\n",
    "            for key2, _ in result[key].items():\n",
    "                result[key][key2] = average_experiment_dict(result[key][key2])\n",
    "        \n",
    "    output_file_1 = open(\"impressions.csv\", \"w\")\n",
    "\n",
    "    for click_model in final:\n",
    "        for interleaving in final[click_model]:\n",
    "\n",
    "            output_file_1.write(\"{},-,{},\\n\".format(click_model, interleaving))\n",
    "            output_file_1.write(\"\\n\")\n",
    "            output_file_1.write(\"bin,max,min,median,stdev,mean,whole_list,\\n\")\n",
    "\n",
    "            for bin in final[click_model][interleaving]:\n",
    "\n",
    "                listbuilder = \"\"\n",
    "                for element in final[click_model][interleaving][bin][\"list\"]:\n",
    "                    listbuilder = listbuilder + str(element) + \",\"\n",
    "\n",
    "                max = final[click_model][interleaving][bin][\"max\"]\n",
    "                min = final[click_model][interleaving][bin][\"min\"]\n",
    "                median = final[click_model][interleaving][bin][\"median\"]\n",
    "                mean = final[click_model][interleaving][bin][\"mean\"]\n",
    "                stdev = final[click_model][interleaving][bin][\"std\"]\n",
    "\n",
    "                bin_output = \"{},{},{},{},{},{},{},\\n\".format(bin, max, min, median, stdev, mean, listbuilder)\n",
    "                output_file_1.write(bin_output)\n",
    "\n",
    "            output_file_1.write(\"\\n\")\n",
    "            output_file_1.write(\"\\n\")\n",
    "\n",
    "\n",
    "    output_file_1.close()\n",
    "\n",
    "    output_file_2 = open(\"wins.csv\", \"w\")\n",
    "\n",
    "    for click_model in result:\n",
    "        for interleaving in result[click_model]:\n",
    "\n",
    "            output_file_2.write(\"{},-,{},\\n\".format(click_model, interleaving))\n",
    "            output_file_2.write(\"\\n\")\n",
    "            output_file_2.write(\"bin,whole_list,\\n\")\n",
    "\n",
    "            for bin in result[click_model][interleaving]:\n",
    "\n",
    "                listbuilder = \"\"\n",
    "                for element in result[click_model][interleaving][bin]:\n",
    "                    listbuilder = listbuilder + str(element) + \",\"\n",
    "\n",
    "                bin_output = \"{},{},\\n\".format(bin, listbuilder)\n",
    "\n",
    "                output_file_2.write(bin_output)\n",
    "\n",
    "            output_file_2.write(\"\\n\")\n",
    "            output_file_2.write(\"\\n\")\n",
    "\n",
    "    output_file_2.close()\n",
    "    \n",
    "    print(\"Finished csv export\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: caching disabled, nothing will be pickled. See boolean CACHING_ON on top of notebook\n",
      "Building data framework\n",
      "Created data model, this only needs to be done once if caching is on\n",
      "Starting step 1\n",
      "Goal:Simulate Rankings of Relevance for E and P\n",
      "\n",
      "\n",
      "--- generating documents...\n",
      "--- generating rankings...\n",
      "--- generating ranking pairs...\n",
      "--- finished generating 14400 ranking pairs\n",
      "\n",
      "\n",
      "Finished step 1\n",
      "\n",
      "\n",
      "Starting step 2\n",
      "Goal:Calculate the 𝛥measure\n",
      "\n",
      "\n",
      "total ranking pairs left: 6192\n",
      "Finished step 2\n",
      "Starting step 3\n",
      "Goal:Implement Team-Draft Interleaving and Probabilistic Interleaving \n",
      "\n",
      "\n",
      "WARNING: caching disabled, nothing will be pickled. See boolean CACHING_ON on top of notebook\n",
      "\n",
      "Start interleaving category 0\n",
      "1510 out of 1512 done\n",
      "Start interleaving category 1\n",
      "1180 out of 1188 done\n",
      "Start interleaving category 2\n",
      "972 out of 1080 done\n",
      "Start interleaving category 3\n",
      "1180 out of 1188 done\n",
      "Start interleaving category 4\n",
      "750 out of 756 done\n",
      "Start interleaving category 5\n",
      "320 out of 324 done\n",
      "Start interleaving category 6\n",
      "140 out of 144 done\n",
      "Start interleaving category 7\n",
      "\n",
      "Start interleaving category 8\n",
      "\n",
      "Start interleaving category 9\n",
      "\n",
      "\n",
      "\n",
      "Finished step 3\n",
      "Starting step 4\n",
      "Goal:Simulate User Clicks\n",
      "\n",
      "\n",
      "Attempting loading gamma's from pickle\n",
      "WARNING: caching disabled, nothing will be pickled. See boolean CACHING_ON on top of notebook\n",
      "Did not find gamma's saved in pickle so will retrain and save\n",
      "Starting training\n",
      "EM iteration number = 13 Trained parameters = [0.9749, 0.6143, 0.423]]\n",
      "\n",
      "Attempting loading rho's from pickle\n",
      "Did not find rho saved in pickle so will retrain and save\n",
      "Starting training\n",
      "Final rho parameter 0.2733908531057551\n",
      "Finished step 4\n",
      "Starting step 5\n",
      "Goal:Simulate Interleaving Experiment\n",
      "\n",
      "\n",
      "Running experiments: 1/4\n",
      "WARNING: caching disabled, nothing will be pickled. See boolean CACHING_ON on top of notebook\n",
      "Started multiprocessing 1\n",
      "Running experiments: 2/4\n",
      "Started multiprocessing 2\n",
      "Running experiments: 3/4\n",
      "Started multiprocessing 3\n",
      "Running experiments: 4/4\n",
      "Started multiprocessing 4\n",
      "Suggestion: in terminal enter 'tail -1000f [LOGFILE]' to follow progress of this part\n",
      "Waiting for result experiment, please be patient\n",
      "See logfiles of multiprocesses 'Console_output_multiprocess_#.txt'(only available if filewriting is enabled)\n",
      "\n",
      "Got result back from experiment 4\n",
      "\n",
      "Waiting for result experiment, please be patient\n",
      "See logfiles of multiprocesses 'Console_output_multiprocess_#.txt'(only available if filewriting is enabled)\n",
      "\n",
      "Got result back from experiment 2\n",
      "\n",
      "Waiting for result experiment, please be patient\n",
      "See logfiles of multiprocesses 'Console_output_multiprocess_#.txt'(only available if filewriting is enabled)\n",
      "\n",
      "Got result back from experiment 3\n",
      "\n",
      "Waiting for result experiment, please be patient\n",
      "See logfiles of multiprocesses 'Console_output_multiprocess_#.txt'(only available if filewriting is enabled)\n",
      "\n",
      "Got result back from experiment 1\n",
      "\n",
      "Attempting joining back in multiprocess\n",
      "\n",
      "Joined experiment 1 back in sucessfully\n",
      "\n",
      "Attempting joining back in multiprocess\n",
      "\n",
      "Joined experiment 2 back in sucessfully\n",
      "\n",
      "Attempting joining back in multiprocess\n",
      "\n",
      "Joined experiment 3 back in sucessfully\n",
      "\n",
      "Attempting joining back in multiprocess\n",
      "\n",
      "Joined experiment 4 back in sucessfully\n",
      "\n",
      "Running experiments: Done!\n",
      "Finished step 5\n",
      "Starting step 6\n",
      "Goal:Compute Sample Size\n",
      "\n",
      "\n",
      "Calculating: Done!\n",
      "Finished step 6\n",
      "#######\n",
      "\n",
      "\n",
      "DONE\n",
      "\n",
      "\n",
      "\n",
      "Starting csv export\n",
      "WARNING: caching disabled, nothing will be pickled. See boolean CACHING_ON on top of notebook\n",
      "Finished csv export\n",
      "\n",
      "\n",
      "Some performance statistics:\n",
      "         14210293 function calls (13687573 primitive calls) in 110.962 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        6    0.000    0.000  110.679   18.446 <ipython-input-18-5844353abb93>:22(do_next_step)\n",
      "        6    0.000    0.000  110.679   18.446 <ipython-input-3-2a6a3c6b38df>:8(do_step)\n",
      "        1    0.000    0.000   98.868   98.868 <ipython-input-16-f10594fc93e4>:6(onStart)\n",
      "        4    0.000    0.000   98.846   24.711 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/queues.py:91(get)\n",
      "        4    0.000    0.000   98.845   24.711 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:208(recv_bytes)\n",
      "        4    0.000    0.000   98.845   24.711 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:406(_recv_bytes)\n",
      "        8    0.000    0.000   98.845   12.356 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:374(_recv)\n",
      "        8   98.844   12.356   98.844   12.356 {built-in method posix.read}\n",
      "        1    0.032    0.032    7.212    7.212 <ipython-input-14-0b74c1ae1bb4>:7(onStart)\n",
      "        1    0.041    0.041    6.939    6.939 <ipython-input-12-bfcbf25c6fc6>:8(train)\n",
      "        1    0.025    0.025    3.997    3.997 <ipython-input-10-de456b0809c9>:7(onStart)\n",
      "       13    2.779    0.214    3.948    0.304 <ipython-input-12-bfcbf25c6fc6>:100(alpha_update)\n",
      "    12384    0.025    0.000    3.925    0.000 <ipython-input-7-64393e3cd0c7>:11(__init__)\n",
      "     6192    0.012    0.000    3.119    0.001 <ipython-input-8-1100fb0253a7>:4(__init__)\n",
      "     6192    0.180    0.000    3.093    0.000 <ipython-input-8-1100fb0253a7>:13(_interleave_docs)\n",
      "       13    2.430    0.187    2.430    0.187 <ipython-input-12-bfcbf25c6fc6>:143(gamma_update)\n",
      "    28080    1.065    0.000    1.592    0.000 {method 'choice' of 'mtrand.RandomState' objects}\n",
      "510336/24768    0.463    0.000    1.275    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copy.py:132(deepcopy)\n",
      "       14    1.023    0.073    1.255    0.090 <ipython-input-12-bfcbf25c6fc6>:84(init_alphas)\n",
      "61920/24768    0.074    0.000    1.222    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copy.py:210(_deepcopy_list)\n",
      "     6192    0.006    0.000    0.825    0.000 <ipython-input-9-89802931418e>:3(__init__)\n",
      "     6192    0.069    0.000    0.806    0.000 <ipython-input-9-89802931418e>:6(_interleave_docs)\n",
      "    56160    0.172    0.000    0.742    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copy.py:268(_reconstruct)\n",
      "     6192    0.336    0.000    0.468    0.000 <ipython-input-8-1100fb0253a7>:63(_fill_in_expectations)\n",
      "        1    0.012    0.012    0.428    0.428 <ipython-input-17-52def559d7d0>:11(onStart)\n",
      "        2    0.394    0.197    0.420    0.210 <ipython-input-11-d0ec6b5d28ad>:15(get_sc)\n",
      "  6043324    0.375    0.000    0.375    0.000 {method 'keys' of 'dict' objects}\n",
      "     1521    0.010    0.000    0.360    0.000 <ipython-input-17-52def559d7d0>:88(proportion_test)\n",
      "    28080    0.036    0.000    0.351    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:121(unique)\n",
      "     3042    0.086    0.000    0.350    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1878(ppf)\n",
      "    56160    0.083    0.000    0.297    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copy.py:236(_deepcopy_dict)\n",
      "    28080    0.196    0.000    0.279    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:268(_unique1d)\n",
      "        1    0.182    0.182    0.260    0.260 <ipython-input-2-1726ad626a78>:40(load_data_model_1)\n",
      "        1    0.012    0.012    0.241    0.241 <ipython-input-13-df9771c2ee25>:8(train)\n",
      "        1    0.105    0.105    0.240    0.240 <ipython-input-12-bfcbf25c6fc6>:64(get_uq)\n",
      "     9129    0.011    0.000    0.195    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:524(argsreduce)\n",
      "     9129    0.031    0.000    0.144    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:549(<listcomp>)\n",
      "        1    0.007    0.007    0.135    0.135 <ipython-input-6-58fe5fc4e5a8>:6(onStart)\n",
      "    28800    0.112    0.000    0.127    0.000 <ipython-input-6-58fe5fc4e5a8>:40(calculate_err)\n",
      "    58525    0.030    0.000    0.125    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:49(_wrapfunc)\n",
      "    70101    0.038    0.000    0.124    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/random.py:252(choice)\n",
      "    28080    0.024    0.000    0.115    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2092(cumsum)\n",
      "    15216    0.018    0.000    0.113    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:1516(extract)\n",
      "  1086800    0.113    0.000    0.113    0.000 {method 'get' of 'dict' objects}\n",
      "   174240    0.077    0.000    0.104    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copy.py:252(_keep_alive)\n",
      "   112320    0.026    0.000    0.088    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copy.py:273(<genexpr>)\n",
      "    56160    0.053    0.000    0.083    0.000 <ipython-input-7-64393e3cd0c7>:71(_remove_duplicates_from_other_ranking)\n",
      "   159552    0.082    0.000    0.082    0.000 <ipython-input-8-1100fb0253a7>:72(<listcomp>)\n",
      "    70101    0.056    0.000    0.081    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/random.py:222(_randbelow)\n",
      "   113228    0.023    0.000    0.072    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numeric.py:504(asanyarray)\n",
      "  1053700    0.072    0.000    0.072    0.000 {method 'append' of 'list' objects}\n",
      "    28080    0.066    0.000    0.066    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "   125447    0.059    0.000    0.059    0.000 {built-in method numpy.core.multiarray.array}\n",
      "   883588    0.057    0.000    0.057    0.000 {built-in method builtins.id}\n",
      "   270094    0.056    0.000    0.056    0.000 {built-in method builtins.sum}\n",
      "    30432    0.016    0.000    0.050    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1471(ravel)\n",
      "       28    0.003    0.000    0.050    0.002 <ipython-input-1-ce8967d9b0a7>:102(average_chunks)\n",
      "    28081    0.019    0.000    0.046    0.000 <ipython-input-1-ce8967d9b0a7>:39(softmax)\n",
      "   173967    0.045    0.000    0.045    0.000 {built-in method builtins.getattr}\n",
      "     5612    0.004    0.000    0.045    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:272(average)\n",
      "    56160    0.040    0.000    0.040    0.000 {method '__reduce_ex__' of 'object' objects}\n",
      "     9129    0.014    0.000    0.038    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/shape_base.py:11(atleast_1d)\n",
      "        1    0.001    0.001    0.037    0.037 <ipython-input-5-621e32cc6327>:6(onStart)\n",
      "        1    0.035    0.035    0.035    0.035 <ipython-input-5-621e32cc6327>:17(<listcomp>)\n",
      "    28080    0.028    0.000    0.034    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/getlimits.py:376(__new__)\n",
      "   450648    0.032    0.000    0.032    0.000 {built-in method builtins.len}\n",
      "     5612    0.002    0.000    0.031    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
      "     5668    0.011    0.000    0.030    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/_methods.py:58(_mean)\n",
      "    42652    0.028    0.000    0.028    0.000 <ipython-input-2-1726ad626a78>:68(<listcomp>)\n",
      "    56160    0.020    0.000    0.028    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copyreg.py:87(__newobj__)\n",
      "   111478    0.027    0.000    0.027    0.000 {method 'pop' of 'list' objects}\n",
      "    15216    0.007    0.000    0.027    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:86(take)\n",
      "    28080    0.014    0.000    0.027    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numeric.py:371(count_nonzero)\n",
      "    31122    0.027    0.000    0.027    0.000 {built-in method numpy.core.multiarray.empty}\n",
      "   100000    0.027    0.000    0.027    0.000 {method 'split' of 'str' objects}\n",
      "    28080    0.026    0.000    0.026    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "    61919    0.025    0.000    0.025    0.000 {built-in method builtins.hasattr}\n",
      "   175881    0.023    0.000    0.023    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.022    0.022    0.023    0.023 <ipython-input-19-b694180b46eb>:11(csv_ing_it)\n",
      "     3045    0.002    0.000    0.022    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1933(any)\n",
      "    12384    0.022    0.000    0.022    0.000 <ipython-input-7-64393e3cd0c7>:63(cut_off_at)\n",
      "    28108    0.022    0.000    0.022    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "     3101    0.005    0.000    0.021    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:64(_wrapreduction)\n",
      "   317952    0.020    0.000    0.020    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copy.py:190(_deepcopy_atomic)\n",
      "     8825    0.019    0.000    0.019    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     3042    0.008    0.000    0.019    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/_lib/_util.py:14(_valarray)\n",
      "   140645    0.018    0.000    0.018    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "    56160    0.018    0.000    0.018    0.000 <ipython-input-7-64393e3cd0c7>:75(<listcomp>)\n",
      "    15216    0.004    0.000    0.018    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1577(nonzero)\n",
      "    28081    0.017    0.000    0.017    0.000 <ipython-input-1-ce8967d9b0a7>:43(<listcomp>)\n",
      "   100000    0.017    0.000    0.017    0.000 {method 'replace' of 'str' objects}\n",
      "    28080    0.011    0.000    0.016    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:113(_unpack_tuple)\n",
      "    37152    0.010    0.000    0.015    0.000 <ipython-input-8-1100fb0253a7>:58(_pop_distribution)\n",
      "   259200    0.015    0.000    0.015    0.000 <ipython-input-4-41e03c483bef>:10(relevance_to_int)\n",
      "        4    0.000    0.000    0.015    0.004 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/process.py:95(start)\n",
      "     3045    0.003    0.000    0.014    0.000 {method 'any' of 'numpy.generic' objects}\n",
      "        4    0.000    0.000    0.014    0.004 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/context.py:221(_Popen)\n",
      "        4    0.000    0.000    0.014    0.004 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/context.py:274(_Popen)\n",
      "    15216    0.014    0.000    0.014    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.014    0.003 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/popen_fork.py:16(__init__)\n",
      "    28080    0.013    0.000    0.013    0.000 {built-in method numpy.core.multiarray.count_nonzero}\n",
      "     9129    0.004    0.000    0.013    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:1567(place)\n",
      "    15216    0.012    0.000    0.012    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "    56160    0.012    0.000    0.012    0.000 {method 'update' of 'dict' objects}\n",
      "    12193    0.002    0.000    0.012    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numeric.py:433(asarray)\n",
      "     3045    0.001    0.000    0.011    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/_methods.py:42(_any)\n",
      "    30445    0.010    0.000    0.010    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.010    0.003 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/popen_fork.py:64(_launch)\n",
      "        4    0.009    0.002    0.009    0.002 {built-in method posix.fork}\n",
      "    59261    0.008    0.000    0.008    0.000 {method 'items' of 'dict' objects}\n",
      "      173    0.001    0.000    0.008    0.000 {built-in method builtins.print}\n",
      "    67746    0.008    0.000    0.008    0.000 {built-in method builtins.issubclass}\n",
      "    56164    0.008    0.000    0.008    0.000 {built-in method __new__ of type object at 0x55d061c71fe0}\n",
      "      346    0.001    0.000    0.008    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/site-packages/ipykernel/iostream.py:382(write)\n",
      "     3042    0.002    0.000    0.007    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numeric.py:156(ones)\n",
      "     9129    0.007    0.000    0.007    0.000 {built-in method numpy.core.multiarray._insert}\n",
      "    70101    0.007    0.000    0.007    0.000 {method 'bit_length' of 'int' objects}\n",
      "      404    0.001    0.000    0.006    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/site-packages/ipykernel/iostream.py:195(schedule)\n",
      "    15216    0.006    0.000    0.006    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "     5696    0.005    0.000    0.005    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/_methods.py:48(_count_reduce_items)\n",
      "    18144    0.005    0.000    0.005    0.000 {method 'index' of 'list' objects}\n",
      "     3042    0.001    0.000    0.005    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py:160(_ppf)\n",
      "      404    0.004    0.000    0.004    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/site-packages/zmq/sugar/socket.py:334(send)\n",
      "       10    0.000    0.000    0.004    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/popen_fork.py:25(poll)\n",
      "     3042    0.004    0.000    0.004    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py:97(_norm_ppf)\n",
      "       10    0.004    0.000    0.004    0.000 {built-in method posix.waitpid}\n",
      "     3042    0.004    0.000    0.004    0.000 {built-in method numpy.core.multiarray.copyto}\n",
      "        8    0.000    0.000    0.003    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/site-packages/ipykernel/iostream.py:334(flush)\n",
      "      444    0.003    0.000    0.003    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        8    0.000    0.000    0.003    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:533(wait)\n",
      "        4    0.000    0.000    0.003    0.001 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/process.py:115(join)\n",
      "        4    0.000    0.000    0.003    0.001 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/popen_fork.py:44(wait)\n",
      "        8    0.000    0.000    0.003    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:263(wait)\n",
      "       28    0.000    0.000    0.002    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:3254(median)\n",
      "       28    0.000    0.000    0.002    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:3199(_ureduce)\n",
      "       28    0.000    0.000    0.002    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:3342(_median)\n",
      "       28    0.001    0.000    0.001    0.000 <ipython-input-1-ce8967d9b0a7>:94(split_to_chunks)\n",
      "       28    0.000    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2923(std)\n",
      "       13    0.000    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/linalg/linalg.py:2203(norm)\n",
      "       28    0.000    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/_methods.py:138(_std)\n",
      "        1    0.000    0.000    0.001    0.001 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/context.py:99(Queue)\n",
      "     9072    0.001    0.000    0.001    0.000 <ipython-input-7-64393e3cd0c7>:90(_pop_distribution)\n",
      "      412    0.000    0.000    0.001    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:1104(is_alive)\n",
      "       28    0.000    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/_methods.py:91(_var)\n",
      "      518    0.000    0.000    0.001    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/codecs.py:318(decode)\n",
      "       56    0.000    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2817(mean)\n",
      "        3    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:958(_find_and_load)\n",
      "        4    0.001    0.000    0.001    0.000 {built-in method _pickle.loads}\n",
      "       13    0.001    0.000    0.001    0.000 {built-in method numpy.core.multiarray.dot}\n",
      "        3    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:931(_find_and_load_unlocked)\n",
      "     3045    0.001    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1656(shape)\n",
      "     3045    0.001    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:863(_argcheck)\n",
      "     3045    0.001    0.000    0.001    0.000 <string>:2(_parse_args)\n",
      "        3    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:641(_load_unlocked)\n",
      "        1    0.000    0.000    0.001    0.001 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/queues.py:36(__init__)\n",
      "       28    0.000    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/lib/utils.py:1119(_median_nancheck)\n",
      "        4    0.000    0.000    0.001    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/process.py:52(_cleanup)\n",
      "       28    0.000    0.000    0.001    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2227(amax)\n",
      "        3    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:672(exec_module)\n",
      "      518    0.001    0.000    0.001    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-10-de456b0809c9>:20(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1626(pdf)\n",
      "      346    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/site-packages/ipykernel/iostream.py:320(_schedule_flush)\n",
      "      212    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "       28    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2337(amin)\n",
      "      346    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/site-packages/ipykernel/iostream.py:307(_is_master_process)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "      412    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:1062(_wait_for_tstate_lock)\n",
      "       28    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numeric.py:1524(moveaxis)\n",
      "      120    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "       13    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2734(around)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:743(get_code)\n",
      "       28    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:601(partition)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:95(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:51(__init__)\n",
      "       13    0.000    0.000    0.000    0.000 {method 'round' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:197(_call_with_frames_removed)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/context.py:64(Lock)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "      404    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/site-packages/ipykernel/iostream.py:93(_event_pipe)\n",
      "        2    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:162(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
      "      370    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "       56    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numeric.py:1468(normalize_axis_tuple)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
      "       28    0.000    0.000    0.000    0.000 {method 'partition' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:485(_compile_bytecode)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method marshal.loads}\n",
      "       56    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numerictypes.py:687(issubdtype)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:861(_find_spec)\n",
      "       10    0.000    0.000    0.000    0.000 <ipython-input-2-1726ad626a78>:24(load_python_obj)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/util.py:151(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/util.py:167(__call__)\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:115(_make_name)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1149(find_spec)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1117(_get_spec)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:11(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/tempfile.py:157(__next__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)\n",
      "      112    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numerictypes.py:619(issubclass_)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'write' of '_io.BytesIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/queues.py:10(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-17-52def559d7d0>:102(onfinish)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-14-0b74c1ae1bb4>:33(onfinish)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/tempfile.py:146(rng)\n",
      "      412    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:506(is_set)\n",
      "        8    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:498(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:553(module_from_spec)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:830(get_data)\n",
      "        2    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:130(__del__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:493(_init_module_attrs)\n",
      "        2    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:360(_close)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:75(_path_stat)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numerictypes.py:950(find_common_type)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/context.py:84(BoundedSemaphore)\n",
      "        9    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:215(__init__)\n",
      "      112    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numeric.py:1515(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:145(__init__)\n",
      "      412    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        6    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numerictypes.py:927(_can_coerce_all)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-16-f10594fc93e4>:25(<listcomp>)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.zeros}\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/tempfile.py:160(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:263(cache_from_source)\n",
      "       19    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:989(_handle_fromlist)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:146(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/process.py:71(__init__)\n",
      "       18    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:57(_path_join)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:389(cached)\n",
      "       28    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:98(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:361(_get_cached)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/random.py:87(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py:141(_pdf)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/util.py:136(register_after_fork)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/random.py:96(seed)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/popen_fork.py:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py:81(_norm_pdf)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-16-f10594fc93e4>:100(onfinish)\n",
      "       28    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/ma/core.py:6200(isMaskedArray)\n",
      "       19    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:402(parent)\n",
      "       28    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:430(_validate_bytecode_header)\n",
      "       40    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:501(Pipe)\n",
      "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f9a865cf840}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1228(_get_spec)\n",
      "       18    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:59(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:159(_get_module_lock)\n",
      "       28    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "       28    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/weakref.py:165(__setitem__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:840(path_stats)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'read' of '_io.FileIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-10-de456b0809c9>:57(onfinish)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-621e32cc6327>:23(onfinish)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-6-58fe5fc4e5a8>:37(onfinish)\n",
      "       56    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.normalize_axis_index}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:94(_path_isfile)\n",
      "       31    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/queues.py:67(_after_fork)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:304(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:85(_path_is_mode_type)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:153(__exit__)\n",
      "       28    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/_bootlocale.py:23(getpreferredencoding)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:524(spec_from_file_location)\n",
      "       23    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "       13    0.000    0.000    0.000    0.000 <ipython-input-12-bfcbf25c6fc6>:151(<dictcomp>)\n",
      "       13    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/linalg/linalg.py:113(isComplexType)\n",
      "        8    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:239(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:102(release)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.putmask}\n",
      "       28    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numeric.py:1586(<listcomp>)\n",
      "        9    0.000    0.000    0.000    0.000 <ipython-input-2-1726ad626a78>:10(save_python_obj)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/weakref.py:109(remove)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:57(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:77(acquire)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-621e32cc6327>:26(generate_documents)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:875(_support_mask)\n",
      "       56    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "       42    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numerictypes.py:936(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       42    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:372(Barrier)\n",
      "        5    0.000    0.000    0.000    0.000 <ipython-input-2-1726ad626a78>:5(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:251(_acquire_restore)\n",
      "        8    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:242(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/_weakrefset.py:81(add)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:63(_path_split)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/copyreg.py:96(_slotnames)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:52(_r_long)\n",
      "       21    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:208(_verbose_message)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _imp.lock_held}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/queues.py:34(Queue)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-13-df9771c2ee25>:4(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-621e32cc6327>:3(__init__)\n",
      "       22    0.000    0.000    0.000    0.000 <ipython-input-1-ce8967d9b0a7>:45(difference_to_err_table_position)\n",
      "        6    0.000    0.000    0.000    0.000 <ipython-input-3-2a6a3c6b38df>:3(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:117(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/context.py:232(get_context)\n",
      "        8    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:254(_is_owned)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/weakref.py:339(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/weakref.py:334(__new__)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/_weakrefset.py:38(_remove)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:771(find_spec)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:393(_check_name_wrapper)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:91(_make_methods)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-17-52def559d7d0>:4(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 <ipython-input-15-aa22a34d5fc6>:5(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-12-bfcbf25c6fc6>:4(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <ipython-input-11-d0ec6b5d28ad>:4(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 <ipython-input-4-41e03c483bef>:3(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numerictypes.py:1001(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "        8    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/threading.py:248(_release_save)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:800(__init__)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:834(__enter__)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:838(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
      "        8    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/popen_fork.py:13(Popen)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:211(Condition)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:47(SemLock)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-1-ce8967d9b0a7>:71(initialize_err_table)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/util.py:48(debug)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:138(_check_readable)\n",
      "        8    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/process.py:83(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/codecs.py:308(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:825(get_filename)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1080(_path_importer_cache)\n",
      "        2    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/codecs.py:185(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:293(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:297(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:355(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:173(cb)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:124(Semaphore)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/queues.py:276(JoinableQueue)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-16-f10594fc93e4>:2(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-14-0b74c1ae1bb4>:3(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-6-58fe5fc4e5a8>:3(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-10-de456b0809c9>:3(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/codecs.py:259(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:307(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:41(_relax_case)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:142(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
      "        8    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:333(Event)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:143(BoundedSemaphore)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:160(Lock)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/synchronize.py:185(RLock)\n",
      "        1    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/queues.py:318(SimpleQueue)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/.local/lib/python3.6/site-packages/numpy/core/numerictypes.py:1002(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/util.py:44(sub_debug)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/context.py:186(get_context)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/context.py:196(get_start_method)\n",
      "        4    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/connection.py:134(_check_closed)\n",
      "        3    0.000    0.000    0.000    0.000 /home/stijnverdenius/miniconda3/envs/ml1labs/lib/python3.6/multiprocessing/process.py:35(current_process)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:669(create_module)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:410(has_location)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:698(find_spec)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "See 'wins.csv' & 'impressions.csv' for results of experiments for 'the percentage of wins' in the experiment of algorithm E and its resulting 'needed impressions for statistical significance' respectively\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully deleted logfiles\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    results, percentages, pr  = main()\n",
    "    try:\n",
    "        csv_ing_it(results, percentages)\n",
    "    except Exception as e:\n",
    "        print(\"csv file writing failed, error:\")\n",
    "        print(str(e))\n",
    "    \n",
    "    print(\"Some performance statistics:\")\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    sortby = 'cumulative'\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "    ps.print_stats()\n",
    "    print (s.getvalue())   # COMMENT OUT TO IGNORE TIME PERFORMANCE\n",
    "    print(\"\\n\\n\\nSee 'wins.csv' & 'impressions.csv' for results of experiments for 'the percentage of wins' in the experiment of algorithm E and its resulting 'needed impressions for statistical significance' respectively\\n\\n\\n\")\n",
    "    \n",
    "    try:# removing log files\n",
    "        for x in range(1,5):\n",
    "            os.system(\"rm Console_output_multiprocess_{}.txt\".format(x))\n",
    "        print(\"Sucessfully deleted logfiles\")\n",
    "    except:\n",
    "        print(\"Failed to remove logfiles, you might wanna look at that yourself\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "- INSERT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
